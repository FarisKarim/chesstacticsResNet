{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9_NOvcI5q65F",
    "outputId": "a193222a-afab-4792-f772-5b2d693a0f8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-chess\n",
      "  Downloading python_chess-1.999-py3-none-any.whl.metadata (776 bytes)\n",
      "Collecting chess<2,>=1 (from python-chess)\n",
      "  Downloading chess-1.11.2.tar.gz (6.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Downloading python_chess-1.999-py3-none-any.whl (1.4 kB)\n",
      "Building wheels for collected packages: chess\n",
      "  Building wheel for chess (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for chess: filename=chess-1.11.2-py3-none-any.whl size=147776 sha256=af0b62f4dcacae11523acf2b8516aca616655e344b32a05a9ffe5411c370fbbb\n",
      "  Stored in directory: /root/.cache/pip/wheels/fb/5d/5c/59a62d8a695285e59ec9c1f66add6f8a9ac4152499a2be0113\n",
      "Successfully built chess\n",
      "Installing collected packages: chess, python-chess\n",
      "Successfully installed chess-1.11.2 python-chess-1.999\n"
     ]
    }
   ],
   "source": [
    "!pip install python-chess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kLt7rU0eq-sq"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import chess\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "np.complex_ = np.complex128\n",
    "np.float_ = np.float64\n",
    "np.string_ = np.bytes_\n",
    "np.unicode_ = np.str_\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Yt-Idz8rVe3",
    "outputId": "e3cacdfa-9596-4298-9132-8abbef400af2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8iJAgBOAXveM"
   },
   "outputs": [],
   "source": [
    "file_path = '/content/drive/MyDrive/lichess_db_puzzle.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 556
    },
    "id": "b1Ssjne_X0yb",
    "outputId": "8df418dd-cd31-4b5e-816e-e68b3759b393"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-b1c78785-8330-419a-8f2b-26caa611643a\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PuzzleId</th>\n",
       "      <th>FEN</th>\n",
       "      <th>Moves</th>\n",
       "      <th>Rating</th>\n",
       "      <th>RatingDeviation</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>NbPlays</th>\n",
       "      <th>Themes</th>\n",
       "      <th>GameUrl</th>\n",
       "      <th>OpeningTags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00008</td>\n",
       "      <td>r6k/pp2r2p/4Rp1Q/3p4/8/1N1P2R1/PqP2bPP/7K b - ...</td>\n",
       "      <td>f2g3 e6e7 b2b1 b3c1 b1c1 h6c1</td>\n",
       "      <td>1942</td>\n",
       "      <td>75</td>\n",
       "      <td>95</td>\n",
       "      <td>7530</td>\n",
       "      <td>crushing hangingPiece long middlegame</td>\n",
       "      <td>https://lichess.org/787zsVup/black#48</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000D</td>\n",
       "      <td>5rk1/1p3ppp/pq3b2/8/8/1P1Q1N2/P4PPP/3R2K1 w - ...</td>\n",
       "      <td>d3d6 f8d8 d6d8 f6d8</td>\n",
       "      <td>1405</td>\n",
       "      <td>74</td>\n",
       "      <td>96</td>\n",
       "      <td>30875</td>\n",
       "      <td>advantage endgame short</td>\n",
       "      <td>https://lichess.org/F8M8OS71#53</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0008Q</td>\n",
       "      <td>8/4R3/1p2P3/p4r2/P6p/1P3Pk1/4K3/8 w - - 1 64</td>\n",
       "      <td>e7f7 f5e5 e2f1 e5e6</td>\n",
       "      <td>1257</td>\n",
       "      <td>78</td>\n",
       "      <td>90</td>\n",
       "      <td>688</td>\n",
       "      <td>advantage endgame rookEndgame short</td>\n",
       "      <td>https://lichess.org/MQSyb3KW#127</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0009B</td>\n",
       "      <td>r2qr1k1/b1p2ppp/pp4n1/P1P1p3/4P1n1/B2P2Pb/3NBP...</td>\n",
       "      <td>b6c5 e2g4 h3g4 d1g4</td>\n",
       "      <td>1080</td>\n",
       "      <td>74</td>\n",
       "      <td>87</td>\n",
       "      <td>586</td>\n",
       "      <td>advantage middlegame short</td>\n",
       "      <td>https://lichess.org/4MWQCxQ6/black#32</td>\n",
       "      <td>Kings_Pawn_Game Kings_Pawn_Game_Leonardis_Vari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000VW</td>\n",
       "      <td>r4r2/1p3pkp/p5p1/3R1N1Q/3P4/8/P1q2P2/3R2K1 b -...</td>\n",
       "      <td>g6f5 d5c5 c2e4 h5g5 g7h8 g5f6</td>\n",
       "      <td>2844</td>\n",
       "      <td>104</td>\n",
       "      <td>85</td>\n",
       "      <td>246</td>\n",
       "      <td>crushing endgame long</td>\n",
       "      <td>https://lichess.org/e9AY2m5j/black#50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b1c78785-8330-419a-8f2b-26caa611643a')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-b1c78785-8330-419a-8f2b-26caa611643a button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-b1c78785-8330-419a-8f2b-26caa611643a');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-2799b5c2-8abc-4664-b84c-738e553cf2d5\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2799b5c2-8abc-4664-b84c-738e553cf2d5')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-2799b5c2-8abc-4664-b84c-738e553cf2d5 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "  PuzzleId                                                FEN  \\\n",
       "0    00008  r6k/pp2r2p/4Rp1Q/3p4/8/1N1P2R1/PqP2bPP/7K b - ...   \n",
       "1    0000D  5rk1/1p3ppp/pq3b2/8/8/1P1Q1N2/P4PPP/3R2K1 w - ...   \n",
       "2    0008Q       8/4R3/1p2P3/p4r2/P6p/1P3Pk1/4K3/8 w - - 1 64   \n",
       "3    0009B  r2qr1k1/b1p2ppp/pp4n1/P1P1p3/4P1n1/B2P2Pb/3NBP...   \n",
       "4    000VW  r4r2/1p3pkp/p5p1/3R1N1Q/3P4/8/P1q2P2/3R2K1 b -...   \n",
       "\n",
       "                           Moves  Rating  RatingDeviation  Popularity  \\\n",
       "0  f2g3 e6e7 b2b1 b3c1 b1c1 h6c1    1942               75          95   \n",
       "1            d3d6 f8d8 d6d8 f6d8    1405               74          96   \n",
       "2            e7f7 f5e5 e2f1 e5e6    1257               78          90   \n",
       "3            b6c5 e2g4 h3g4 d1g4    1080               74          87   \n",
       "4  g6f5 d5c5 c2e4 h5g5 g7h8 g5f6    2844              104          85   \n",
       "\n",
       "   NbPlays                                 Themes  \\\n",
       "0     7530  crushing hangingPiece long middlegame   \n",
       "1    30875                advantage endgame short   \n",
       "2      688    advantage endgame rookEndgame short   \n",
       "3      586             advantage middlegame short   \n",
       "4      246                  crushing endgame long   \n",
       "\n",
       "                                 GameUrl  \\\n",
       "0  https://lichess.org/787zsVup/black#48   \n",
       "1        https://lichess.org/F8M8OS71#53   \n",
       "2       https://lichess.org/MQSyb3KW#127   \n",
       "3  https://lichess.org/4MWQCxQ6/black#32   \n",
       "4  https://lichess.org/e9AY2m5j/black#50   \n",
       "\n",
       "                                         OpeningTags  \n",
       "0                                                NaN  \n",
       "1                                                NaN  \n",
       "2                                                NaN  \n",
       "3  Kings_Pawn_Game Kings_Pawn_Game_Leonardis_Vari...  \n",
       "4                                                NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "TTyli-K6rYqf",
    "outputId": "166150d6-e426-4de4-f482-aafda4f5ebf4"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-2cfb7ba9-52c1-4b42-929a-78ee856c40ca\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PuzzleId</th>\n",
       "      <th>FEN</th>\n",
       "      <th>Moves</th>\n",
       "      <th>Rating</th>\n",
       "      <th>RatingDeviation</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>NbPlays</th>\n",
       "      <th>Themes</th>\n",
       "      <th>GameUrl</th>\n",
       "      <th>OpeningTags</th>\n",
       "      <th>ParsedThemes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00008</td>\n",
       "      <td>r6k/pp2r2p/4Rp1Q/3p4/8/1N1P2R1/PqP2bPP/7K b - ...</td>\n",
       "      <td>f2g3 e6e7 b2b1 b3c1 b1c1 h6c1</td>\n",
       "      <td>1942</td>\n",
       "      <td>75</td>\n",
       "      <td>95</td>\n",
       "      <td>7530</td>\n",
       "      <td>crushing hangingPiece long middlegame</td>\n",
       "      <td>https://lichess.org/787zsVup/black#48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[crushing, hangingPiece, long, middlegame]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000D</td>\n",
       "      <td>5rk1/1p3ppp/pq3b2/8/8/1P1Q1N2/P4PPP/3R2K1 w - ...</td>\n",
       "      <td>d3d6 f8d8 d6d8 f6d8</td>\n",
       "      <td>1405</td>\n",
       "      <td>74</td>\n",
       "      <td>96</td>\n",
       "      <td>30875</td>\n",
       "      <td>advantage endgame short</td>\n",
       "      <td>https://lichess.org/F8M8OS71#53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[advantage, endgame, short]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0008Q</td>\n",
       "      <td>8/4R3/1p2P3/p4r2/P6p/1P3Pk1/4K3/8 w - - 1 64</td>\n",
       "      <td>e7f7 f5e5 e2f1 e5e6</td>\n",
       "      <td>1257</td>\n",
       "      <td>78</td>\n",
       "      <td>90</td>\n",
       "      <td>688</td>\n",
       "      <td>advantage endgame rookEndgame short</td>\n",
       "      <td>https://lichess.org/MQSyb3KW#127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[advantage, endgame, rookEndgame, short]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0009B</td>\n",
       "      <td>r2qr1k1/b1p2ppp/pp4n1/P1P1p3/4P1n1/B2P2Pb/3NBP...</td>\n",
       "      <td>b6c5 e2g4 h3g4 d1g4</td>\n",
       "      <td>1080</td>\n",
       "      <td>74</td>\n",
       "      <td>87</td>\n",
       "      <td>586</td>\n",
       "      <td>advantage middlegame short</td>\n",
       "      <td>https://lichess.org/4MWQCxQ6/black#32</td>\n",
       "      <td>Kings_Pawn_Game Kings_Pawn_Game_Leonardis_Vari...</td>\n",
       "      <td>[advantage, middlegame, short]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000VW</td>\n",
       "      <td>r4r2/1p3pkp/p5p1/3R1N1Q/3P4/8/P1q2P2/3R2K1 b -...</td>\n",
       "      <td>g6f5 d5c5 c2e4 h5g5 g7h8 g5f6</td>\n",
       "      <td>2844</td>\n",
       "      <td>104</td>\n",
       "      <td>85</td>\n",
       "      <td>246</td>\n",
       "      <td>crushing endgame long</td>\n",
       "      <td>https://lichess.org/e9AY2m5j/black#50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[crushing, endgame, long]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>000Vc</td>\n",
       "      <td>8/8/4k1p1/2KpP2p/5PP1/8/8/8 w - - 0 53</td>\n",
       "      <td>g4h5 g6h5 f4f5 e6e5 f5f6 e5f6</td>\n",
       "      <td>1575</td>\n",
       "      <td>80</td>\n",
       "      <td>75</td>\n",
       "      <td>102</td>\n",
       "      <td>crushing endgame long pawnEndgame</td>\n",
       "      <td>https://lichess.org/l6AejDMO#105</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[crushing, endgame, long, pawnEndgame]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>000Zo</td>\n",
       "      <td>4r3/1k6/pp3r2/1b2P2p/3R1p2/P1R2P2/1P4PP/6K1 w ...</td>\n",
       "      <td>e5f6 e8e1 g1f2 e1f1</td>\n",
       "      <td>1353</td>\n",
       "      <td>75</td>\n",
       "      <td>86</td>\n",
       "      <td>627</td>\n",
       "      <td>endgame mate mateIn2 short</td>\n",
       "      <td>https://lichess.org/n8Ff742v#69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[endgame, mate, mateIn2, short]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>000aY</td>\n",
       "      <td>r4rk1/pp3ppp/2n1b3/q1pp2B1/8/P1Q2NP1/1PP1PP1P/...</td>\n",
       "      <td>g5e7 a5c3 b2c3 c6e7</td>\n",
       "      <td>1440</td>\n",
       "      <td>79</td>\n",
       "      <td>74</td>\n",
       "      <td>512</td>\n",
       "      <td>advantage master middlegame short</td>\n",
       "      <td>https://lichess.org/iihZGl6t#29</td>\n",
       "      <td>Benoni_Defense Benoni_Defense_Benoni-Indian_De...</td>\n",
       "      <td>[advantage, master, middlegame, short]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>000hf</td>\n",
       "      <td>r1bqk2r/pp1nbNp1/2p1p2p/8/2BP4/1PN3P1/P3QP1P/3...</td>\n",
       "      <td>e8f7 e2e6 f7f8 e6f7</td>\n",
       "      <td>1483</td>\n",
       "      <td>76</td>\n",
       "      <td>91</td>\n",
       "      <td>566</td>\n",
       "      <td>mate mateIn2 middlegame short</td>\n",
       "      <td>https://lichess.org/71ygsFeE/black#38</td>\n",
       "      <td>Horwitz_Defense Horwitz_Defense_Other_variations</td>\n",
       "      <td>[mate, mateIn2, middlegame, short]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>000lC</td>\n",
       "      <td>3r3r/pQNk1ppp/1qnb1n2/1B6/8/8/PPP3PP/3R1R1K w ...</td>\n",
       "      <td>d1d6 d7d6 b7b6 a7b6</td>\n",
       "      <td>1408</td>\n",
       "      <td>76</td>\n",
       "      <td>94</td>\n",
       "      <td>3489</td>\n",
       "      <td>advantage hangingPiece middlegame short</td>\n",
       "      <td>https://lichess.org/vaqz2bx6#37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[advantage, hangingPiece, middlegame, short]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2cfb7ba9-52c1-4b42-929a-78ee856c40ca')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-2cfb7ba9-52c1-4b42-929a-78ee856c40ca button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-2cfb7ba9-52c1-4b42-929a-78ee856c40ca');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-fc31ee12-b789-4198-bf87-17cfb52c72ce\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fc31ee12-b789-4198-bf87-17cfb52c72ce')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-fc31ee12-b789-4198-bf87-17cfb52c72ce button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "  PuzzleId                                                FEN  \\\n",
       "0    00008  r6k/pp2r2p/4Rp1Q/3p4/8/1N1P2R1/PqP2bPP/7K b - ...   \n",
       "1    0000D  5rk1/1p3ppp/pq3b2/8/8/1P1Q1N2/P4PPP/3R2K1 w - ...   \n",
       "2    0008Q       8/4R3/1p2P3/p4r2/P6p/1P3Pk1/4K3/8 w - - 1 64   \n",
       "3    0009B  r2qr1k1/b1p2ppp/pp4n1/P1P1p3/4P1n1/B2P2Pb/3NBP...   \n",
       "4    000VW  r4r2/1p3pkp/p5p1/3R1N1Q/3P4/8/P1q2P2/3R2K1 b -...   \n",
       "5    000Vc             8/8/4k1p1/2KpP2p/5PP1/8/8/8 w - - 0 53   \n",
       "6    000Zo  4r3/1k6/pp3r2/1b2P2p/3R1p2/P1R2P2/1P4PP/6K1 w ...   \n",
       "7    000aY  r4rk1/pp3ppp/2n1b3/q1pp2B1/8/P1Q2NP1/1PP1PP1P/...   \n",
       "8    000hf  r1bqk2r/pp1nbNp1/2p1p2p/8/2BP4/1PN3P1/P3QP1P/3...   \n",
       "9    000lC  3r3r/pQNk1ppp/1qnb1n2/1B6/8/8/PPP3PP/3R1R1K w ...   \n",
       "\n",
       "                           Moves  Rating  RatingDeviation  Popularity  \\\n",
       "0  f2g3 e6e7 b2b1 b3c1 b1c1 h6c1    1942               75          95   \n",
       "1            d3d6 f8d8 d6d8 f6d8    1405               74          96   \n",
       "2            e7f7 f5e5 e2f1 e5e6    1257               78          90   \n",
       "3            b6c5 e2g4 h3g4 d1g4    1080               74          87   \n",
       "4  g6f5 d5c5 c2e4 h5g5 g7h8 g5f6    2844              104          85   \n",
       "5  g4h5 g6h5 f4f5 e6e5 f5f6 e5f6    1575               80          75   \n",
       "6            e5f6 e8e1 g1f2 e1f1    1353               75          86   \n",
       "7            g5e7 a5c3 b2c3 c6e7    1440               79          74   \n",
       "8            e8f7 e2e6 f7f8 e6f7    1483               76          91   \n",
       "9            d1d6 d7d6 b7b6 a7b6    1408               76          94   \n",
       "\n",
       "   NbPlays                                   Themes  \\\n",
       "0     7530    crushing hangingPiece long middlegame   \n",
       "1    30875                  advantage endgame short   \n",
       "2      688      advantage endgame rookEndgame short   \n",
       "3      586               advantage middlegame short   \n",
       "4      246                    crushing endgame long   \n",
       "5      102        crushing endgame long pawnEndgame   \n",
       "6      627               endgame mate mateIn2 short   \n",
       "7      512        advantage master middlegame short   \n",
       "8      566            mate mateIn2 middlegame short   \n",
       "9     3489  advantage hangingPiece middlegame short   \n",
       "\n",
       "                                 GameUrl  \\\n",
       "0  https://lichess.org/787zsVup/black#48   \n",
       "1        https://lichess.org/F8M8OS71#53   \n",
       "2       https://lichess.org/MQSyb3KW#127   \n",
       "3  https://lichess.org/4MWQCxQ6/black#32   \n",
       "4  https://lichess.org/e9AY2m5j/black#50   \n",
       "5       https://lichess.org/l6AejDMO#105   \n",
       "6        https://lichess.org/n8Ff742v#69   \n",
       "7        https://lichess.org/iihZGl6t#29   \n",
       "8  https://lichess.org/71ygsFeE/black#38   \n",
       "9        https://lichess.org/vaqz2bx6#37   \n",
       "\n",
       "                                         OpeningTags  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3  Kings_Pawn_Game Kings_Pawn_Game_Leonardis_Vari...   \n",
       "4                                                NaN   \n",
       "5                                                NaN   \n",
       "6                                                NaN   \n",
       "7  Benoni_Defense Benoni_Defense_Benoni-Indian_De...   \n",
       "8   Horwitz_Defense Horwitz_Defense_Other_variations   \n",
       "9                                                NaN   \n",
       "\n",
       "                                   ParsedThemes  \n",
       "0    [crushing, hangingPiece, long, middlegame]  \n",
       "1                   [advantage, endgame, short]  \n",
       "2      [advantage, endgame, rookEndgame, short]  \n",
       "3                [advantage, middlegame, short]  \n",
       "4                     [crushing, endgame, long]  \n",
       "5        [crushing, endgame, long, pawnEndgame]  \n",
       "6               [endgame, mate, mateIn2, short]  \n",
       "7        [advantage, master, middlegame, short]  \n",
       "8            [mate, mateIn2, middlegame, short]  \n",
       "9  [advantage, hangingPiece, middlegame, short]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_themes(theme_string):\n",
    "    if isinstance(theme_string, str):\n",
    "        return theme_string.split()\n",
    "\n",
    "df['ParsedThemes'] = df['Themes'].apply(parse_themes)\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ml-vipO_W_q2",
    "outputId": "64336995-a529-4fd5-aba5-664460f08592"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'crushing': 1935186,\n",
       "         'hangingPiece': 197090,\n",
       "         'long': 1198539,\n",
       "         'middlegame': 2243593,\n",
       "         'advantage': 1444247,\n",
       "         'endgame': 2294763,\n",
       "         'short': 2542764,\n",
       "         'rookEndgame': 238060,\n",
       "         'pawnEndgame': 154339,\n",
       "         'mate': 1326242,\n",
       "         'mateIn2': 581354,\n",
       "         'master': 665816,\n",
       "         'exposedKing': 134930,\n",
       "         'skewer': 105612,\n",
       "         'fork': 654030,\n",
       "         'trappedPiece': 62260,\n",
       "         'pin': 296286,\n",
       "         'veryLong': 380967,\n",
       "         'backRankMate': 152242,\n",
       "         'discoveredAttack': 256331,\n",
       "         'sacrifice': 342756,\n",
       "         'quietMove': 191324,\n",
       "         'bishopEndgame': 60341,\n",
       "         'mateIn1': 578940,\n",
       "         'oneMove': 625704,\n",
       "         'bodenMate': 2376,\n",
       "         'deflection': 203176,\n",
       "         'kingsideAttack': 391533,\n",
       "         'smotheredMate': 15909,\n",
       "         'advancedPawn': 277093,\n",
       "         'attraction': 166049,\n",
       "         'promotion': 106151,\n",
       "         'mateIn3': 141136,\n",
       "         'masterVsMaster': 68307,\n",
       "         'superGM': 2871,\n",
       "         'opening': 257421,\n",
       "         'queensideAttack': 67481,\n",
       "         'interference': 18206,\n",
       "         'defensiveMove': 287422,\n",
       "         'queenEndgame': 48781,\n",
       "         'attackingF2F7': 31972,\n",
       "         'queenRookEndgame': 33148,\n",
       "         'clearance': 63084,\n",
       "         'intermezzo': 63471,\n",
       "         'equality': 42296,\n",
       "         'knightEndgame': 37204,\n",
       "         'hookMate': 7363,\n",
       "         'xRayAttack': 16443,\n",
       "         'capturingDefender': 36170,\n",
       "         'doubleBishopMate': 2397,\n",
       "         'arabianMate': 5119,\n",
       "         'doubleCheck': 23282,\n",
       "         'mateIn4': 20392,\n",
       "         'zugzwang': 43542,\n",
       "         'enPassant': 6894,\n",
       "         'vukovicMate': 1804,\n",
       "         'dovetailMate': 2715,\n",
       "         'killBoxMate': 3672,\n",
       "         'anastasiaMate': 5225,\n",
       "         'castling': 2252,\n",
       "         'mateIn5': 4420,\n",
       "         'underPromotion': 872})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from collections import Counter\n",
    "\n",
    "all_labels = [label for labels in df[\"ParsedThemes\"] for label in labels]\n",
    "label_counter = Counter(all_labels)\n",
    "\n",
    "label_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dlXhZZevrdmN",
    "outputId": "b35ec465-a11c-4491-a1b6-c4a4b14bdc99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     ParsedThemes              CoreLabel\n",
      "0      [crushing, hangingPiece, long, middlegame]         [hangingPiece]\n",
      "1        [advantage, endgame, rookEndgame, short]          [rookEndgame]\n",
      "2          [crushing, endgame, long, pawnEndgame]          [pawnEndgame]\n",
      "3                 [endgame, mate, mateIn2, short]                 [mate]\n",
      "4              [mate, mateIn2, middlegame, short]                 [mate]\n",
      "5    [advantage, hangingPiece, middlegame, short]         [hangingPiece]\n",
      "6  [crushing, endgame, exposedKing, long, skewer]  [skewer, exposedKing]\n",
      "7        [crushing, endgame, fork, master, short]                 [fork]\n",
      "8             [advantage, fork, long, middlegame]                 [fork]\n",
      "9                [advantage, endgame, pin, short]                  [pin]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3188480"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import ast\n",
    "\n",
    "\n",
    "allowed_set = {\"mate\", \"fork\", \"pin\", \"sacrifice\", \"skewer\", \"advancedPawn\", \"exposedKing\", \"rookEndgame\", \"pawnEndgame\", \"hangingPiece\", \"discoveredAttack\"}\n",
    "\n",
    "def select_core_label(themes):\n",
    "    \"\"\"\n",
    "    For a list of themes, convert any mate variants to 'mate',\n",
    "    then keep only those in allowed_set.\n",
    "    If multiple remain, choose one at random.\n",
    "    Returns None if no allowed label is found.\n",
    "    \"\"\"\n",
    "    selected = []\n",
    "    for label in themes:\n",
    "        # Merge any label containing 'mate' (case-insensitive) into \"mate\"\n",
    "        if \"mate\" in label.lower():\n",
    "            selected.append(\"mate\")\n",
    "        elif label in allowed_set:\n",
    "            selected.append(label)\n",
    "    # Remove duplicates\n",
    "    selected = list(set(selected))\n",
    "    return list(set(selected))\n",
    "\n",
    "import ast\n",
    "if df[\"ParsedThemes\"].apply(lambda x: isinstance(x, str)).any():\n",
    "    df[\"ParsedThemes\"] = df[\"ParsedThemes\"].apply(ast.literal_eval)\n",
    "\n",
    "df[\"CoreLabel\"] = df[\"ParsedThemes\"].apply(select_core_label)\n",
    "\n",
    "core_tactics_df = df[df[\"CoreLabel\"].apply(lambda x: len(x) > 0)].copy()\n",
    "core_tactics_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(core_tactics_df[[\"ParsedThemes\", \"CoreLabel\"]].head(10))\n",
    "len(core_tactics_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 429
    },
    "id": "xyZ6qgNismBU",
    "outputId": "76cc2abc-8faf-4098-b8df-0fc3201c78f2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000000/1000000 [01:56<00:00, 8608.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"label_counts_df\",\n  \"rows\": 11,\n  \"fields\": [\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11,\n        \"samples\": [\n          \"discoveredAttack\",\n          \"mate\",\n          \"exposedKing\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 110667,\n        \"min\": 33133,\n        \"max\": 416540,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          80289,\n          416540,\n          42069\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "label_counts_df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-f8747b11-1dbe-4b6f-bc45-fb35f0f01146\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mate</td>\n",
       "      <td>416540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fork</td>\n",
       "      <td>204822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sacrifice</td>\n",
       "      <td>107544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pin</td>\n",
       "      <td>92874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>advancedPawn</td>\n",
       "      <td>86627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>discoveredAttack</td>\n",
       "      <td>80289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rookEndgame</td>\n",
       "      <td>74796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hangingPiece</td>\n",
       "      <td>61892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pawnEndgame</td>\n",
       "      <td>47991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>exposedKing</td>\n",
       "      <td>42069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>skewer</td>\n",
       "      <td>33133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f8747b11-1dbe-4b6f-bc45-fb35f0f01146')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-f8747b11-1dbe-4b6f-bc45-fb35f0f01146 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-f8747b11-1dbe-4b6f-bc45-fb35f0f01146');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-f8c62fe3-3595-4a7f-8e41-d642f06d849a\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f8c62fe3-3595-4a7f-8e41-d642f06d849a')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-f8c62fe3-3595-4a7f-8e41-d642f06d849a button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "  <div id=\"id_32e005c2-e729-45ab-9040-35289f96f507\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('label_counts_df')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_32e005c2-e729-45ab-9040-35289f96f507 button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('label_counts_df');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "               Label   Count\n",
       "3               mate  416540\n",
       "6               fork  204822\n",
       "8          sacrifice  107544\n",
       "7                pin   92874\n",
       "10      advancedPawn   86627\n",
       "9   discoveredAttack   80289\n",
       "1        rookEndgame   74796\n",
       "0       hangingPiece   61892\n",
       "2        pawnEndgame   47991\n",
       "5        exposedKing   42069\n",
       "4             skewer   33133"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "sample = core_tactics_df.head(1000000).copy()\n",
    "\n",
    "# Extract first move from the Moves column\n",
    "sample[\"FirstMove\"] = sample[\"Moves\"].str.split().str[0]\n",
    "\n",
    "# Apply the first move to each FEN\n",
    "updated_fens = []\n",
    "for fen, move in tqdm(zip(sample[\"FEN\"], sample[\"FirstMove\"]), total=len(sample)):\n",
    "    try:\n",
    "        board = chess.Board(fen)\n",
    "        board.push_uci(move)\n",
    "        updated_fens.append(board.fen())\n",
    "    except:\n",
    "        updated_fens.append(None)\n",
    "\n",
    "sample[\"FEN_after_first_move\"] = updated_fens\n",
    "\n",
    "# Drop failed rows\n",
    "sample = sample.dropna(subset=[\"FEN_after_first_move\"]).reset_index(drop=True)\n",
    "\n",
    "print(len(sample))\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "\n",
    "all_labels = list(chain.from_iterable(sample[\"CoreLabel\"]))\n",
    "label_counts = Counter(all_labels)\n",
    "\n",
    "label_counts_df = pd.DataFrame(label_counts.items(), columns=[\"Label\", \"Count\"]).sort_values(by=\"Count\", ascending=False)\n",
    "display(label_counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lIUsNuGJsqXW"
   },
   "outputs": [],
   "source": [
    "piece_to_channel = {\n",
    "    'P': 0, 'N': 1, 'B': 2, 'R': 3, 'Q': 4, 'K': 5,\n",
    "    'p': 6, 'n': 7, 'b': 8, 'r': 9, 'q': 10, 'k': 11\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XonbJdEJs2Ne",
    "outputId": "296d9922-bd23-41ad-ecdf-2b512344f4ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example FEN: r6k/pp2r2p/4Rp1Q/3p4/8/1N1P2b1/PqP3PP/7K w - - 0 25\n",
      "Refined board array shape: (8, 8, 19)\n"
     ]
    }
   ],
   "source": [
    "def fen_to_board_array(fen):\n",
    "    \"\"\"\n",
    "    Converts a FEN string into an 8x8x19 numpy array.\n",
    "    Channels:\n",
    "      0-11: Basic one-hot encoding for pieces.\n",
    "      12: Attacked by White (1 if square is attacked by at least one white piece).\n",
    "      13: Attacked by Black.\n",
    "      14: White kingside castling rights (entire plane: 1 if available, else 0).\n",
    "      15: White queenside castling rights.\n",
    "      16: Black kingside castling rights.\n",
    "      17: Black queenside castling rights.\n",
    "      18: Side-to-move (entire plane: 1 if White, 0 if Black).\n",
    "    \"\"\"\n",
    "    board = chess.Board(fen)\n",
    "    board_array = np.zeros((8, 8, 19), dtype=np.float32)\n",
    "    # --- 8x8x12 one-hot encoding for pieces ---\n",
    "    for square, piece in board.piece_map().items():\n",
    "        row = square // 8\n",
    "        col = square % 8\n",
    "        channel = piece_to_channel[piece.symbol()]\n",
    "        board_array[row, col, channel] = 1.0\n",
    "    # --- Attacked squares channels ---\n",
    "    # Channel 12: attacked by white; Channel 13: attacked by black.\n",
    "    for square in chess.SQUARES:\n",
    "        row = square // 8\n",
    "        col = square % 8\n",
    "        if board.is_attacked_by(chess.WHITE, square):\n",
    "            board_array[row, col, 12] = 1.0\n",
    "        if board.is_attacked_by(chess.BLACK, square):\n",
    "            board_array[row, col, 13] = 1.0\n",
    "\n",
    "    # --- Castling rights channels ---\n",
    "    # Channels 14-17: constant planes for castling rights.\n",
    "    castling_channels = [14, 15, 16, 17]\n",
    "    # White kingside\n",
    "    flag = 1.0 if board.has_kingside_castling_rights(chess.WHITE) else 0.0\n",
    "    board_array[:, :, 14] = flag\n",
    "    # White queenside\n",
    "    flag = 1.0 if board.has_queenside_castling_rights(chess.WHITE) else 0.0\n",
    "    board_array[:, :, 15] = flag\n",
    "    # Black kingside\n",
    "    flag = 1.0 if board.has_kingside_castling_rights(chess.BLACK) else 0.0\n",
    "    board_array[:, :, 16] = flag\n",
    "    # Black queenside\n",
    "    flag = 1.0 if board.has_queenside_castling_rights(chess.BLACK) else 0.0\n",
    "    board_array[:, :, 17] = flag\n",
    "\n",
    "    # --- Side-to-move channel ---\n",
    "    # Channel 18: fill the plane with 1 if White's turn, else 0.\n",
    "    side = 1.0 if board.turn == chess.WHITE else 0.0\n",
    "    board_array[:, :, 18] = side\n",
    "\n",
    "    return board_array\n",
    "\n",
    "example_fen = sample[\"FEN_after_first_move\"].iloc[0]\n",
    "refined_board = fen_to_board_array(example_fen)\n",
    "print(\"Example FEN:\", example_fen)\n",
    "print(\"Refined board array shape:\", refined_board.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZtNc19q0tZfj",
    "outputId": "2e495bc2-e690-4739-db16-643fce34be49"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting FENs to board arrays: 100%|██████████| 1000000/1000000 [04:29<00:00, 3708.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000000, 8, 8, 19)\n",
      "y shape: (1000000, 11)\n",
      "Label space (all parsed themes): ['advancedPawn' 'discoveredAttack' 'exposedKing' 'fork' 'hangingPiece'\n",
      " 'mate' 'pawnEndgame' 'pin' 'rookEndgame' 'sacrifice' 'skewer']\n"
     ]
    }
   ],
   "source": [
    "X_list = []\n",
    "for fen in tqdm(sample[\"FEN_after_first_move\"], desc=\"Converting FENs to board arrays\"):\n",
    "    board_array = fen_to_board_array(fen)\n",
    "    X_list.append(board_array)\n",
    "X = np.array(X_list)\n",
    "print(\"X shape:\", X.shape)\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(sample[\"CoreLabel\"])\n",
    "print(\"y shape:\", y.shape)\n",
    "print(\"Label space (all parsed themes):\", mlb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zG97AfgJteIg"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "jTGTSHdetjVk",
    "outputId": "bf721283-d1cb-4858-b0ca-4e29db143495"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">10,944</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,864</span> │ re_lu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,864</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_2… │\n",
       "│                           │                        │                │ re_lu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,864</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_3     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_3… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,864</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_4     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_4… │\n",
       "│                           │                        │                │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ re_lu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,864</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_5     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ re_lu_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_5… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,864</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_6     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_6… │\n",
       "│                           │                        │                │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ re_lu_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,864</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_7     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ re_lu_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_7… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,864</span> │ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_8     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ add_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_8… │\n",
       "│                           │                        │                │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ re_lu_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">73,728</span> │ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_9     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ re_lu_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_9… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,456</span> │ dropout_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_10    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_11    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ add_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
       "│                           │                        │                │ batch_normalization_1… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ re_lu_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,456</span> │ dropout_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_12    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ re_lu_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,456</span> │ dropout_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_13    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ add_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
       "│                           │                        │                │ dropout_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ re_lu_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,456</span> │ dropout_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_14    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ re_lu_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,456</span> │ dropout_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_15    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ add_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
       "│                           │                        │                │ dropout_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ re_lu_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,456</span> │ dropout_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_16    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ re_lu_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,456</span> │ dropout_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_17    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ add_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
       "│                           │                        │                │ dropout_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ re_lu_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">294,912</span> │ dropout_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_18    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ re_lu_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ dropout_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32,768</span> │ dropout_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_19    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_20    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ add_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
       "│                           │                        │                │ batch_normalization_2… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ re_lu_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ dropout_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_21    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ re_lu_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_2… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ dropout_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_22    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ add_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_2… │\n",
       "│                           │                        │                │ dropout_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ re_lu_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ global_average_pooling2d  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)  │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,827</span> │ global_average_poolin… │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m19\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │         \u001b[38;5;34m10,944\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │            \u001b[38;5;34m256\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ re_lu (\u001b[38;5;33mReLU\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ batch_normalization[\u001b[38;5;34m0\u001b[0m… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │         \u001b[38;5;34m36,864\u001b[0m │ re_lu[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │            \u001b[38;5;34m256\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ re_lu_1 (\u001b[38;5;33mReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ re_lu_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │         \u001b[38;5;34m36,864\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │            \u001b[38;5;34m256\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ add (\u001b[38;5;33mAdd\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_2… │\n",
       "│                           │                        │                │ re_lu[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ re_lu_2 (\u001b[38;5;33mReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ re_lu_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │         \u001b[38;5;34m36,864\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_3     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │            \u001b[38;5;34m256\u001b[0m │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ re_lu_3 (\u001b[38;5;33mReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_3… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ re_lu_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │         \u001b[38;5;34m36,864\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_4     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │            \u001b[38;5;34m256\u001b[0m │ conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_4… │\n",
       "│                           │                        │                │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ re_lu_4 (\u001b[38;5;33mReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ re_lu_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │         \u001b[38;5;34m36,864\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_5     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │            \u001b[38;5;34m256\u001b[0m │ conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ re_lu_5 (\u001b[38;5;33mReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_5… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ re_lu_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │         \u001b[38;5;34m36,864\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_6     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │            \u001b[38;5;34m256\u001b[0m │ conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ add_2 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_6… │\n",
       "│                           │                        │                │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ re_lu_6 (\u001b[38;5;33mReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ re_lu_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │         \u001b[38;5;34m36,864\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_7     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │            \u001b[38;5;34m256\u001b[0m │ conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ re_lu_7 (\u001b[38;5;33mReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_7… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ re_lu_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │         \u001b[38;5;34m36,864\u001b[0m │ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_8     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │            \u001b[38;5;34m256\u001b[0m │ conv2d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ add_3 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_8… │\n",
       "│                           │                        │                │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ re_lu_8 (\u001b[38;5;33mReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ re_lu_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │         \u001b[38;5;34m73,728\u001b[0m │ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_9     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │            \u001b[38;5;34m512\u001b[0m │ conv2d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ re_lu_9 (\u001b[38;5;33mReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_9… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ re_lu_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m147,456\u001b[0m │ dropout_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │          \u001b[38;5;34m8,192\u001b[0m │ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_10    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │            \u001b[38;5;34m512\u001b[0m │ conv2d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_11    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │            \u001b[38;5;34m512\u001b[0m │ conv2d_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ add_4 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
       "│                           │                        │                │ batch_normalization_1… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ re_lu_10 (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ re_lu_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m147,456\u001b[0m │ dropout_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_12    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │            \u001b[38;5;34m512\u001b[0m │ conv2d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ re_lu_11 (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ re_lu_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m147,456\u001b[0m │ dropout_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_13    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │            \u001b[38;5;34m512\u001b[0m │ conv2d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ add_5 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
       "│                           │                        │                │ dropout_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ re_lu_12 (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ re_lu_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m147,456\u001b[0m │ dropout_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_14    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │            \u001b[38;5;34m512\u001b[0m │ conv2d_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ re_lu_13 (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ re_lu_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m147,456\u001b[0m │ dropout_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_15    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │            \u001b[38;5;34m512\u001b[0m │ conv2d_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ add_6 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
       "│                           │                        │                │ dropout_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ re_lu_14 (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ add_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_13 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ re_lu_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m147,456\u001b[0m │ dropout_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_16    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │            \u001b[38;5;34m512\u001b[0m │ conv2d_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ re_lu_15 (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_14 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ re_lu_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m147,456\u001b[0m │ dropout_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_17    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │            \u001b[38;5;34m512\u001b[0m │ conv2d_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ add_7 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
       "│                           │                        │                │ dropout_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ re_lu_16 (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ add_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_15 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ re_lu_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │        \u001b[38;5;34m294,912\u001b[0m │ dropout_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_18    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ re_lu_17 (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_16 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ re_lu_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_19 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │        \u001b[38;5;34m589,824\u001b[0m │ dropout_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_20 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │         \u001b[38;5;34m32,768\u001b[0m │ dropout_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_19    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_20    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ add_8 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
       "│                           │                        │                │ batch_normalization_2… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ re_lu_18 (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ add_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_17 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ re_lu_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_21 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │        \u001b[38;5;34m589,824\u001b[0m │ dropout_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_21    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ re_lu_19 (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_2… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_18 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ re_lu_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_22 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │        \u001b[38;5;34m589,824\u001b[0m │ dropout_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_22    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ add_9 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_2… │\n",
       "│                           │                        │                │ dropout_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ re_lu_20 (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ add_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_19 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ re_lu_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ global_average_pooling2d  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dropout_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)  │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m)             │          \u001b[38;5;34m2,827\u001b[0m │ global_average_poolin… │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,531,979</span> (13.47 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,531,979\u001b[0m (13.47 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,525,963</span> (13.45 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,525,963\u001b[0m (13.45 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,016</span> (23.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m6,016\u001b[0m (23.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, ReLU, Dropout, Add, GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def residual_block(x, filters, stride=1, dropout_rate=0.3):\n",
    "    shortcut = x\n",
    "\n",
    "    # First convolution\n",
    "    x = Conv2D(filters, (3, 3), strides=stride, padding='same', use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    # Second convolution\n",
    "    x = Conv2D(filters, (3, 3), padding='same', use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # Adjust shortcut if needed\n",
    "    if stride != 1 or shortcut.shape[-1] != filters:\n",
    "        shortcut = Conv2D(filters, (1, 1), strides=stride, padding='same', use_bias=False)(shortcut)\n",
    "        shortcut = BatchNormalization()(shortcut)\n",
    "\n",
    "    # Merge\n",
    "    x = Add()([x, shortcut])\n",
    "    x = ReLU()(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def build_resnet_x(input_shape, num_classes):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    x = Conv2D(64, (3, 3), padding='same', use_bias=False)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    # Stage 1: 64 filters (no downsample)\n",
    "    for _ in range(4):\n",
    "        x = residual_block(x, 64)\n",
    "\n",
    "    # Stage 2: 128 filters (downsample)\n",
    "    x = residual_block(x, 128, stride=2)\n",
    "    for _ in range(3):\n",
    "        x = residual_block(x, 128)\n",
    "\n",
    "    # Stage 3: 256 filters (downsample)\n",
    "    x = residual_block(x, 256, stride=2)\n",
    "    x = residual_block(x, 256)\n",
    "\n",
    "    # Global average pooling and final output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    outputs = Dense(num_classes, activation='sigmoid')(x)\n",
    "\n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "# Usage\n",
    "model = build_resnet_x((8, 8, 19), num_classes=len(mlb.classes_))\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, clipnorm=1.0),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B4mhHRtIuXS6",
    "outputId": "2a0ccdcd-9d5c-4909-9b79-d5b16e2c20c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 10ms/step - accuracy: 0.4610 - loss: 0.2605 - val_accuracy: 0.5654 - val_loss: 0.2078\n",
      "Epoch 2/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.5692 - loss: 0.2038 - val_accuracy: 0.5948 - val_loss: 0.1884\n",
      "Epoch 3/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 9ms/step - accuracy: 0.5924 - loss: 0.1888 - val_accuracy: 0.6256 - val_loss: 0.1705\n",
      "Epoch 4/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 9ms/step - accuracy: 0.6160 - loss: 0.1759 - val_accuracy: 0.6300 - val_loss: 0.1651\n",
      "Epoch 5/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 9ms/step - accuracy: 0.6269 - loss: 0.1694 - val_accuracy: 0.6444 - val_loss: 0.1601\n",
      "Epoch 6/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 9ms/step - accuracy: 0.6361 - loss: 0.1656 - val_accuracy: 0.6568 - val_loss: 0.1547\n",
      "Epoch 7/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6405 - loss: 0.1630 - val_accuracy: 0.6588 - val_loss: 0.1520\n",
      "Epoch 8/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 9ms/step - accuracy: 0.6439 - loss: 0.1607 - val_accuracy: 0.6612 - val_loss: 0.1501\n",
      "Epoch 9/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 9ms/step - accuracy: 0.6478 - loss: 0.1587 - val_accuracy: 0.6625 - val_loss: 0.1485\n",
      "Epoch 10/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6500 - loss: 0.1572 - val_accuracy: 0.6577 - val_loss: 0.1495\n",
      "Epoch 11/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 9ms/step - accuracy: 0.6537 - loss: 0.1557 - val_accuracy: 0.6683 - val_loss: 0.1459\n",
      "Epoch 12/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 9ms/step - accuracy: 0.6562 - loss: 0.1547 - val_accuracy: 0.6665 - val_loss: 0.1467\n",
      "Epoch 13/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 9ms/step - accuracy: 0.6588 - loss: 0.1532 - val_accuracy: 0.6749 - val_loss: 0.1442\n",
      "Epoch 14/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 9ms/step - accuracy: 0.6598 - loss: 0.1522 - val_accuracy: 0.6699 - val_loss: 0.1437\n",
      "Epoch 15/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 9ms/step - accuracy: 0.6606 - loss: 0.1513 - val_accuracy: 0.6746 - val_loss: 0.1435\n",
      "Epoch 16/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6628 - loss: 0.1509 - val_accuracy: 0.6722 - val_loss: 0.1426\n",
      "Epoch 17/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6625 - loss: 0.1504 - val_accuracy: 0.6779 - val_loss: 0.1422\n",
      "Epoch 18/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 9ms/step - accuracy: 0.6654 - loss: 0.1493 - val_accuracy: 0.6782 - val_loss: 0.1414\n",
      "Epoch 19/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6659 - loss: 0.1487 - val_accuracy: 0.6781 - val_loss: 0.1414\n",
      "Epoch 20/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 9ms/step - accuracy: 0.6658 - loss: 0.1484 - val_accuracy: 0.6806 - val_loss: 0.1413\n",
      "Epoch 21/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 9ms/step - accuracy: 0.6682 - loss: 0.1475 - val_accuracy: 0.6813 - val_loss: 0.1395\n",
      "Epoch 22/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6677 - loss: 0.1473 - val_accuracy: 0.6780 - val_loss: 0.1401\n",
      "Epoch 23/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6704 - loss: 0.1466 - val_accuracy: 0.6801 - val_loss: 0.1388\n",
      "Epoch 24/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6701 - loss: 0.1458 - val_accuracy: 0.6821 - val_loss: 0.1384\n",
      "Epoch 25/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6719 - loss: 0.1457 - val_accuracy: 0.6817 - val_loss: 0.1383\n",
      "Epoch 26/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6718 - loss: 0.1451 - val_accuracy: 0.6845 - val_loss: 0.1363\n",
      "Epoch 27/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6726 - loss: 0.1446 - val_accuracy: 0.6792 - val_loss: 0.1373\n",
      "Epoch 28/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6725 - loss: 0.1447 - val_accuracy: 0.6887 - val_loss: 0.1359\n",
      "Epoch 29/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6725 - loss: 0.1443 - val_accuracy: 0.6841 - val_loss: 0.1363\n",
      "Epoch 30/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6740 - loss: 0.1440 - val_accuracy: 0.6826 - val_loss: 0.1369\n",
      "Epoch 31/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6727 - loss: 0.1438 - val_accuracy: 0.6864 - val_loss: 0.1359\n",
      "Epoch 32/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6750 - loss: 0.1434 - val_accuracy: 0.6848 - val_loss: 0.1354\n",
      "Epoch 33/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6761 - loss: 0.1430 - val_accuracy: 0.6870 - val_loss: 0.1347\n",
      "Epoch 34/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6764 - loss: 0.1425 - val_accuracy: 0.6867 - val_loss: 0.1356\n",
      "Epoch 35/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6764 - loss: 0.1423 - val_accuracy: 0.6849 - val_loss: 0.1336\n",
      "Epoch 36/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6767 - loss: 0.1418 - val_accuracy: 0.6884 - val_loss: 0.1343\n",
      "Epoch 37/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6784 - loss: 0.1417 - val_accuracy: 0.6891 - val_loss: 0.1337\n",
      "Epoch 38/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6789 - loss: 0.1413 - val_accuracy: 0.6904 - val_loss: 0.1328\n",
      "Epoch 39/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6784 - loss: 0.1412 - val_accuracy: 0.6927 - val_loss: 0.1337\n",
      "Epoch 40/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6796 - loss: 0.1408 - val_accuracy: 0.6887 - val_loss: 0.1334\n",
      "Epoch 41/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6798 - loss: 0.1409 - val_accuracy: 0.6945 - val_loss: 0.1324\n",
      "Epoch 42/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6802 - loss: 0.1405 - val_accuracy: 0.6928 - val_loss: 0.1317\n",
      "Epoch 43/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6798 - loss: 0.1403 - val_accuracy: 0.6960 - val_loss: 0.1320\n",
      "Epoch 44/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6813 - loss: 0.1399 - val_accuracy: 0.6902 - val_loss: 0.1333\n",
      "Epoch 45/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6802 - loss: 0.1400 - val_accuracy: 0.6929 - val_loss: 0.1325\n",
      "Epoch 46/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6808 - loss: 0.1396 - val_accuracy: 0.6976 - val_loss: 0.1315\n",
      "Epoch 47/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6819 - loss: 0.1393 - val_accuracy: 0.6908 - val_loss: 0.1333\n",
      "Epoch 48/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6819 - loss: 0.1393 - val_accuracy: 0.6918 - val_loss: 0.1321\n",
      "Epoch 49/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6820 - loss: 0.1392 - val_accuracy: 0.6918 - val_loss: 0.1307\n",
      "Epoch 50/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6824 - loss: 0.1391 - val_accuracy: 0.6922 - val_loss: 0.1315\n",
      "Epoch 51/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6826 - loss: 0.1385 - val_accuracy: 0.6971 - val_loss: 0.1306\n",
      "Epoch 52/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6832 - loss: 0.1384 - val_accuracy: 0.6974 - val_loss: 0.1303\n",
      "Epoch 53/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6847 - loss: 0.1383 - val_accuracy: 0.6919 - val_loss: 0.1308\n",
      "Epoch 54/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6820 - loss: 0.1383 - val_accuracy: 0.6967 - val_loss: 0.1308\n",
      "Epoch 55/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6835 - loss: 0.1383 - val_accuracy: 0.6981 - val_loss: 0.1302\n",
      "Epoch 56/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6857 - loss: 0.1377 - val_accuracy: 0.6984 - val_loss: 0.1304\n",
      "Epoch 57/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6839 - loss: 0.1377 - val_accuracy: 0.6945 - val_loss: 0.1296\n",
      "Epoch 58/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6847 - loss: 0.1377 - val_accuracy: 0.6992 - val_loss: 0.1292\n",
      "Epoch 59/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 9ms/step - accuracy: 0.6849 - loss: 0.1374 - val_accuracy: 0.6981 - val_loss: 0.1292\n",
      "Epoch 60/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6855 - loss: 0.1367 - val_accuracy: 0.6993 - val_loss: 0.1296\n",
      "Epoch 61/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6865 - loss: 0.1373 - val_accuracy: 0.6980 - val_loss: 0.1298\n",
      "Epoch 62/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6860 - loss: 0.1373 - val_accuracy: 0.6989 - val_loss: 0.1302\n",
      "Epoch 63/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6862 - loss: 0.1366 - val_accuracy: 0.6961 - val_loss: 0.1294\n",
      "Epoch 64/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6858 - loss: 0.1369 - val_accuracy: 0.6994 - val_loss: 0.1290\n",
      "Epoch 65/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6876 - loss: 0.1366 - val_accuracy: 0.6995 - val_loss: 0.1290\n",
      "Epoch 66/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6872 - loss: 0.1365 - val_accuracy: 0.6976 - val_loss: 0.1285\n",
      "Epoch 67/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6867 - loss: 0.1366 - val_accuracy: 0.6988 - val_loss: 0.1291\n",
      "Epoch 68/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6878 - loss: 0.1363 - val_accuracy: 0.6961 - val_loss: 0.1294\n",
      "Epoch 69/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6864 - loss: 0.1362 - val_accuracy: 0.6981 - val_loss: 0.1286\n",
      "Epoch 70/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6857 - loss: 0.1362 - val_accuracy: 0.7022 - val_loss: 0.1278\n",
      "Epoch 71/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6873 - loss: 0.1358 - val_accuracy: 0.6972 - val_loss: 0.1286\n",
      "Epoch 72/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6885 - loss: 0.1357 - val_accuracy: 0.6985 - val_loss: 0.1290\n",
      "Epoch 73/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6883 - loss: 0.1357 - val_accuracy: 0.6954 - val_loss: 0.1283\n",
      "Epoch 74/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6876 - loss: 0.1358 - val_accuracy: 0.6980 - val_loss: 0.1284\n",
      "Epoch 75/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6874 - loss: 0.1356 - val_accuracy: 0.7007 - val_loss: 0.1281\n",
      "Epoch 76/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6897 - loss: 0.1352 - val_accuracy: 0.7028 - val_loss: 0.1281\n",
      "Epoch 77/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6912 - loss: 0.1350 - val_accuracy: 0.7028 - val_loss: 0.1276\n",
      "Epoch 78/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6907 - loss: 0.1349 - val_accuracy: 0.6981 - val_loss: 0.1285\n",
      "Epoch 79/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6892 - loss: 0.1352 - val_accuracy: 0.7005 - val_loss: 0.1274\n",
      "Epoch 80/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6900 - loss: 0.1349 - val_accuracy: 0.7007 - val_loss: 0.1274\n",
      "Epoch 81/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6896 - loss: 0.1350 - val_accuracy: 0.6990 - val_loss: 0.1273\n",
      "Epoch 82/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6901 - loss: 0.1349 - val_accuracy: 0.7030 - val_loss: 0.1272\n",
      "Epoch 83/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6906 - loss: 0.1345 - val_accuracy: 0.6986 - val_loss: 0.1273\n",
      "Epoch 84/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 9ms/step - accuracy: 0.6905 - loss: 0.1347 - val_accuracy: 0.7034 - val_loss: 0.1273\n",
      "Epoch 85/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 9ms/step - accuracy: 0.6910 - loss: 0.1345 - val_accuracy: 0.6991 - val_loss: 0.1273\n",
      "Epoch 86/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6913 - loss: 0.1343 - val_accuracy: 0.7034 - val_loss: 0.1269\n",
      "Epoch 87/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6907 - loss: 0.1341 - val_accuracy: 0.7027 - val_loss: 0.1265\n",
      "Epoch 88/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6909 - loss: 0.1343 - val_accuracy: 0.7042 - val_loss: 0.1268\n",
      "Epoch 89/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6924 - loss: 0.1341 - val_accuracy: 0.6999 - val_loss: 0.1270\n",
      "Epoch 90/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6910 - loss: 0.1341 - val_accuracy: 0.6997 - val_loss: 0.1273\n",
      "Epoch 91/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6919 - loss: 0.1341 - val_accuracy: 0.7036 - val_loss: 0.1263\n",
      "Epoch 92/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6921 - loss: 0.1335 - val_accuracy: 0.7046 - val_loss: 0.1262\n",
      "Epoch 93/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6926 - loss: 0.1335 - val_accuracy: 0.7024 - val_loss: 0.1265\n",
      "Epoch 94/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6915 - loss: 0.1335 - val_accuracy: 0.7042 - val_loss: 0.1265\n",
      "Epoch 95/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6935 - loss: 0.1332 - val_accuracy: 0.7023 - val_loss: 0.1261\n",
      "Epoch 96/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6920 - loss: 0.1336 - val_accuracy: 0.7048 - val_loss: 0.1264\n",
      "Epoch 97/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6915 - loss: 0.1335 - val_accuracy: 0.7022 - val_loss: 0.1265\n",
      "Epoch 98/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6926 - loss: 0.1333 - val_accuracy: 0.7006 - val_loss: 0.1262\n",
      "Epoch 99/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.6918 - loss: 0.1333 - val_accuracy: 0.7030 - val_loss: 0.1262\n",
      "Epoch 100/100\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 9ms/step - accuracy: 0.6933 - loss: 0.1334 - val_accuracy: 0.7066 - val_loss: 0.1259\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=100,\n",
    "    batch_size=128,\n",
    "    callbacks=[early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yO9n1b6VW3lE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iMlvWEpPuySu"
   },
   "outputs": [],
   "source": [
    "def top_k_accuracy_score_multilabel(y_true, y_pred, k):\n",
    "    num_samples = y_true.shape[0]\n",
    "    hits = 0\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        # Get indices of top-k predicted classes\n",
    "        topk_indices = np.argsort(y_pred[i])[::-1][:k]\n",
    "\n",
    "        # Check if any top-k index is a true label (y_true[i] == 1)\n",
    "        # If y_true[i, topk_idx] == 1 for any of them, it's a 'hit'\n",
    "        if np.any(y_true[i, topk_indices] == 1):\n",
    "            hits += 1\n",
    "\n",
    "    return hits / num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qK0F5W18uzjZ",
    "outputId": "c87656fb-4d1b-42f1-b313-d95caaf5a135"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step\n",
      "F1 Score (micro): 0.7663082004188819\n",
      "Hamming Loss: 0.05274636363636363\n",
      "Top-3 Accuracy: 0.9536\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    advancedPawn       0.73      0.79      0.76     17344\n",
      "discoveredAttack       0.69      0.48      0.57     15955\n",
      "     exposedKing       0.45      0.58      0.51      8292\n",
      "            fork       0.75      0.69      0.72     41166\n",
      "    hangingPiece       0.68      0.91      0.78     12429\n",
      "            mate       0.83      0.95      0.88     83138\n",
      "     pawnEndgame       1.00      1.00      1.00      9603\n",
      "             pin       0.70      0.41      0.51     18726\n",
      "     rookEndgame       0.99      1.00      1.00     15076\n",
      "       sacrifice       0.62      0.47      0.54     21296\n",
      "          skewer       0.63      0.51      0.56      6639\n",
      "\n",
      "       micro avg       0.77      0.76      0.77    249664\n",
      "       macro avg       0.73      0.71      0.71    249664\n",
      "    weighted avg       0.76      0.76      0.76    249664\n",
      "     samples avg       0.78      0.79      0.77    249664\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\Predictions:\n",
      "Sample #1\n",
      "  True Labels:      ('mate',)\n",
      "  Predicted Labels: ('mate',)\n",
      "\n",
      "Sample #2\n",
      "  True Labels:      ('fork',)\n",
      "  Predicted Labels: ('fork',)\n",
      "\n",
      "Sample #3\n",
      "  True Labels:      ('mate',)\n",
      "  Predicted Labels: ('mate',)\n",
      "\n",
      "Sample #4\n",
      "  True Labels:      ('hangingPiece', 'mate')\n",
      "  Predicted Labels: ('hangingPiece', 'mate')\n",
      "\n",
      "Sample #5\n",
      "  True Labels:      ('fork',)\n",
      "  Predicted Labels: ('fork',)\n",
      "\n",
      "Sample #6\n",
      "  True Labels:      ('discoveredAttack', 'mate')\n",
      "  Predicted Labels: ('exposedKing', 'mate')\n",
      "\n",
      "Sample #7\n",
      "  True Labels:      ('skewer',)\n",
      "  Predicted Labels: ('skewer',)\n",
      "\n",
      "Sample #8\n",
      "  True Labels:      ('mate',)\n",
      "  Predicted Labels: ('mate',)\n",
      "\n",
      "Sample #9\n",
      "  True Labels:      ('hangingPiece',)\n",
      "  Predicted Labels: ('hangingPiece',)\n",
      "\n",
      "Sample #10\n",
      "  True Labels:      ('mate',)\n",
      "  Predicted Labels: ('mate',)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, hamming_loss, classification_report, precision_score, recall_score\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_binary = (y_pred > 0.35).astype(int)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred_binary, average='micro')\n",
    "h_loss = hamming_loss(y_test, y_pred_binary)\n",
    "\n",
    "print(\"F1 Score (micro):\", f1)\n",
    "print(\"Hamming Loss:\", h_loss)\n",
    "\n",
    "\n",
    "top3_acc = top_k_accuracy_score_multilabel(y_test, y_pred, k=3)\n",
    "print(f\"Top-3 Accuracy: {top3_acc:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred_binary, target_names=mlb.classes_))\n",
    "\n",
    "true_labels = mlb.inverse_transform(y_test)\n",
    "pred_labels = mlb.inverse_transform(y_pred_binary)\n",
    "print(\"\\Predictions:\")\n",
    "for i in range(10):\n",
    "    print(f\"Sample #{i+1}\")\n",
    "    print(\"  True Labels:     \", true_labels[i])\n",
    "    print(\"  Predicted Labels:\", pred_labels[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "plY7LZD4u3we",
    "outputId": "3ea88678-db40-4a5a-e23e-1a669964a525"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training and validation loss over epochs\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training vs Validation Loss')\n",
    "plt.legend()\n",
    "plt.savefig(\"resnetx.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.savefig(\"resnetx.pdf\", format='pdf', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oaCR_TKT0dw_",
    "outputId": "0aa5eb2a-9dad-492f-fab3-efc5b673b0af"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('/content/drive/MyDrive/resnetx.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9CnPzqQoaSAP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
